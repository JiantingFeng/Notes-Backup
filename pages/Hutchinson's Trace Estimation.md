- Given a matrix $$\bm{A}\in \mathbb{R}^{n\times n}$$, if we want to compute its trace, then we can use this trick, called *Hutchinson's Trace Estimation*.
- $$\mathrm{tr}\left(\bm A\right) = \mathrm{tr}\left(\bm A\mathbb{E}[\varepsilon \varepsilon^T]\right)=\mathbb{E}\left[\mathrm{tr}(\bm{A}\varepsilon\varepsilon^T)\right]=\mathbb{E}\left[\mathrm{tr}(\varepsilon^T\bm{A}\varepsilon)\right] = \mathbb{E}\left[\varepsilon^T\bm{A}\varepsilon\right]$$
- where $$\varepsilon\sim \mathcal{N}(0, \bm I)\in\mathbb{R}^n$$
- then you can use Monte Carlo method to approximate the expectation.
- But, why don't we directly calculate the trace?
- Suppose you need to calculate the trace of a matrix function, i.e. $$\mathrm{tr}(\bm A^2), \mathrm{tr}( \bm A^3)$$, etc
- With traditional way, you should go through the following steps
	- Calculate the Jordan canonical form of $$\bm A$$. Indeed, in numerical computation, every matrix is diagonalizable since all eigenvalues are different (approximation error). Then the cost of this step takes $$\mathcal{O}(n^3)$$, the diag. form is denoted as $$\bm \Lambda$$
	- Calculate $$f(\bm \Lambda)$$, and add them up to calculate trace, which takes $$\mathcal{O}(n)$$
	- Total time complexity is $$\mathcal{O}(n^3)$$
- If we use *Hutchinson's Trace Estimation* to estimate $$\mathrm{tr} \bm A^2$$
	- For $$t=0, 1, \cdots, T$$ do
		- Draw $$\varepsilon\sim \mathcal{N}(0, \bm I)\in\mathbb{R}^n$$
		- Calculate $$\varepsilon^T\bm A^2\varepsilon$$, you can calculate vector-matrix product rather than matrix-matrix product, which takes $$\mathcal{O}(n^2)$$
	- Calculate the average of previous results, takes $$\mathcal{O}(T)$$
	- Total time complexity is $$\mathcal{O}(n^2T)$$
- The vector $$\varepsilon$$ is referred as *probe vector*. If the number of probe vector is smaller than the dimension $$n$$, we can reduce the time complexity.